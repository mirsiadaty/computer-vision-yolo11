# Computer Vision: YOLO

YOLO, which stands for "You Only Look Once," is a popular and efficient object detection algorithm in computer vision. It is known for its speed and ability to perform real-time object detection, making it suitable for applications like autonomous driving and surveillance. 

The original YOLO (You Only Look Once) paper was published in 2015 (https://arxiv.org/abs/1506.02640). Since then, there have been several versions, each improving upon the previous one in terms of speed, accuracy, or both.

YOLO's speed and accuracy make it suitable for various applications, including:
* Autonomous vehicles: Detecting pedestrians, other vehicles, traffic signs, etc. 
* Security and surveillance: Identifying intruders, tracking people in restricted areas. 
* Robotics: Enabling robots to perceive and interact with their environment. 
* Sports analysis: Tracking players and objects. 
* Industrial automation: Detecting defects in manufacturing processes. 

YOLO13 was published June 2025 (https://arxiv.org/abs/2506.17733). Both the convolutional architectures of YOLO11 and earlier versions and the area-based self-attention mechanism introduced in YOLOv12 are limited to local information modeling. YOLO13 enables global multi-to-multi high-order correlations, which improves detection performance in complex scenarios. 
YOLOv13-N improves mAP by 3.0% over YOLO11-N and by 1.5% over YOLOv12-N.


## object tracking

We used version 11 of the model YOLO (You Only Live Once), open-sourced by Ultralytics (https://huggingface.co/Ultralytics/YOLO11). This model is a convolutional neural network CNN.

The following example, we track objects in this video:

https://github.com/user-attachments/assets/ecb20022-cbfa-4f1d-96ce-eef2f420285b

<br>

## object detection

The following are examples of 'object detection' in pictures. 

![tmp6yf0_eyz](https://github.com/user-attachments/assets/e935e5b4-347d-4698-96e1-0e531ff4b9a7)

![tmpa3w8y3f7](https://github.com/user-attachments/assets/030157bd-e701-4056-adc5-53429b85fdeb)

![tmp7zd4ruvw](https://github.com/user-attachments/assets/04e512cd-38a3-45b4-a91c-e17a9c46e460)

The following picture, we had used a Diffusion Generative AI model to create the image. Obviously the image has defects. And YOLO is detecting partial birds.

![tmphfolxyyn](https://github.com/user-attachments/assets/1981e1fa-473c-44dd-af2e-56c40198255b)



The following is excerpt of the code we used for object detection:

```
#https://github.com/ultralytics/ultralytics
from ultralytics import YOLO
import time
# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

FlnmsL = !ls -1 /home/lcluser44/Downloads/*jpeg

print( '22' , time.asctime( time.localtime( time.time() ) ))
#
for ii,vv in enumerate(FlnmsL):
    print( '33' , time.asctime( time.localtime( time.time() ) ))
    print(ii,vv)
    Flnm =vv
    # Perform object detection on an image
    results = model( Flnm )  # Predict on an image
    time.sleep(1)
    #
    results[0].show()  # Display results
    print('---------------------\n\n')
    time.sleep(1)
#
print( '998' , time.asctime( time.localtime( time.time() ) ))
```


![tmpv7f13_c5](https://github.com/user-attachments/assets/7aada6d6-109a-4709-ba22-f13ba67e72f3)

![tmpofr6c_0z](https://github.com/user-attachments/assets/3f15fe21-2e19-4eeb-8fc3-854db9c28884)



REFs:

The raw video taken from:
https://www.vecteezy.com/video/43126621-krakow-poland-02-04-2024-passengers-walking-to-boarding-gate-travelers-with-luggage-in-airport-jetway

Most of the raw pictures were generated by us using Diffusion GenAI.


<br>

<br>

<br>






## fine-tuning

We started from the YOLO11 model, size nano, and used the dataset COCO8 to tune it for 100 epochs on GPU devices of the given machine (https://docs.ultralytics.com/datasets/detect/coco8/).

COCO is a large-scale object detection, segmentation, and captioning dataset (https://cocodataset.org/).

```
from ultralytics import YOLO
# Load a pretrained YOLO11n model
model112 = YOLO("yolo11n.pt")
print( '22' , time.asctime( time.localtime( time.time() ) ))
# Train the model on COCO8
results112 = model112.train(data="coco8.yaml", epochs=100, imgsz=640)
print( '99' , time.asctime( time.localtime( time.time() ) ))
```



The following is the initial part of the tuning log:

```
22 Wed May 21 15:18:58 2025
New https://pypi.org/project/ultralytics/8.3.141 available üòÉ Update with 'pip install -U ultralytics'
Ultralytics 8.3.140 üöÄ Python-3.10.12 torch-2.2.2+cu121 CUDA:0 (Quadro RTX 8000, 48593MiB)
engine/trainer: agnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco8.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None

WARNING ‚ö†Ô∏è Dataset 'coco8.yaml' images not found, missing path '/home/lcluser44/jupyter255/datasets/coco8/images/val'
Downloading https://ultralytics.com/assets/coco8.zip to '/home/lcluser44/jupyter255/datasets/coco8.zip'...

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433k/433k [00:00<00:00, 30.1MB/s]
Unzipping /home/lcluser44/jupyter255/datasets/coco8.zip to /home/lcluser44/jupyter255/datasets/coco8...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 4565.78file/s]

Dataset download success ‚úÖ (0.1s), saved to /home/lcluser44/jupyter255/datasets


Downloading https://ultralytics.com/assets/Arial.ttf to '/home/lcluser44/.config/Ultralytics/Arial.ttf'...

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 45.9MB/s]


                   from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      
  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                
  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     
  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 
 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          
 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           
 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                
 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          
 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           
 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          


YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs

Transferred 499/499 items from pretrained weights
Freezing layer 'model.23.dfl.conv.weight'
AMP: running Automatic Mixed Precision (AMP) checks...
AMP: checks passed ‚úÖ
train: Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1681.9¬±582.4 MB/s, size: 50.0 KB)

train: Scanning /home/lcluser44/jupyter255/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 595.59it/s]

train: New cache created: /home/lcluser44/jupyter255/datasets/coco8/labels/train.cache


val: Fast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1356.4¬±812.4 MB/s, size: 54.0 KB)

val: Scanning /home/lcluser44/jupyter255/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 802.85it/s]

val: New cache created: /home/lcluser44/jupyter255/datasets/coco8/labels/val.cache


Plotting labels to runs/detect/train/labels.jpg... 
optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
optimizer: AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to runs/detect/train
Starting training for 100 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      1/100     0.893G     0.9672      2.354      1.286         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.37s/it]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.26s/it]

                   all          4         17      0.586       0.85      0.878      0.634



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      2/100     0.893G      1.251      3.269      1.644         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.41it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.14it/s]

```










<br>

<br>

and here is the final part of the log:

```
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

     99/100     0.924G     0.4918     0.4948     0.9126         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.25it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.34it/s]

                   all          4         17      0.841      0.483      0.522      0.276



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

    100/100     0.924G     0.4765     0.4869      1.019         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.03it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.06it/s]

                   all          4         17      0.861      0.475      0.523      0.273



100 epochs completed in 0.015 hours.
Optimizer stripped from runs/detect/train/weights/last.pt, 5.6MB
Optimizer stripped from runs/detect/train/weights/best.pt, 5.6MB

Validating runs/detect/train/weights/best.pt...
Ultralytics 8.3.140 üöÄ Python-3.10.12 torch-2.2.2+cu121 CUDA:0 (Quadro RTX 8000, 48593MiB)
YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs

                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.66it/s]

                   all          4         17      0.577       0.85      0.857      0.636
                person          3         10      0.563        0.6      0.632      0.296
                   dog          1          1      0.542          1      0.995      0.796
                 horse          1          2      0.587          1      0.995      0.675
              elephant          1          2      0.353        0.5      0.531      0.259
              umbrella          1          1      0.567          1      0.995      0.895
          potted plant          1          1      0.847          1      0.995      0.895
Speed: 0.3ms preprocess, 3.2ms inference, 0.0ms loss, 1.0ms postprocess per image
Results saved to runs/detect/train
99 Wed May 21 15:20:07 2025

```


<br>

<br>


We then exported the tuned neural net as ONNX and saved into disk files:

```
print( '22' , time.asctime( time.localtime( time.time() ) ))
# Export the model to ONNX format for deployment
path = model112.export(format="onnx")  # Returns the path to the exported model
print( '99' , time.asctime( time.localtime( time.time() ) ))



22 Wed May 21 15:38:52 2025
Ultralytics 8.3.140 üöÄ Python-3.10.12 torch-2.2.2+cu121 CPU (Intel Xeon Silver 4208 2.10GHz)
YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs

PyTorch: starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.3 MB)
requirements: Ultralytics requirement ['onnx>=1.12.0,<1.18.0'] not found, attempting AutoUpdate...
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: onnx<1.18.0,>=1.12.0 in /home/lcluser44/.local/lib/python3.10/site-packages (1.17.0)
Requirement already satisfied: numpy>=1.20 in /home/lcluser44/.local/lib/python3.10/site-packages (from onnx<1.18.0,>=1.12.0) (1.24.4)
Requirement already satisfied: protobuf>=3.20.2 in /home/lcluser44/.local/lib/python3.10/site-packages (from onnx<1.18.0,>=1.12.0) (4.25.2)

requirements: AutoUpdate success ‚úÖ 1.1s
WARNING ‚ö†Ô∏è requirements: Restart runtime or rerun command for updates to take effect


ONNX: starting export with onnx 1.18.0 opset 17...


[notice] A new release of pip is available: 25.0.1 -> 25.1.1
[notice] To update, run: python3 -m pip install --upgrade pip

ONNX: slimming with onnxslim 0.1.53...
ONNX: export success ‚úÖ 2.8s, saved as 'runs/detect/train/weights/best.onnx' (10.2 MB)

Export complete (3.2s)
Results saved to /media/lcluser44/SSD-PUT/mss20230718/ComputerVision/coco2017/runs/detect/train/weights
Predict:         yolo predict task=detect model=runs/detect/train/weights/best.onnx imgsz=640  
Validate:        yolo val task=detect model=runs/detect/train/weights/best.onnx imgsz=640 data=/home/lcluser44/virenv20240420/lib/python3.10/site-packages/ultralytics/cfg/datasets/coco8.yaml  
Visualize:       https://netron.app
99 Wed May 21 15:38:55 2025



!ls -ltA runs/detect/train/weights/

total 21320
-rwxrwxrwx 1 lcluser44 lcluser44 10720972 May 21 15:38 best.onnx
-rwxrwxrwx 1 lcluser44 lcluser44  5551443 May 21 15:20 best.pt
-rwxrwxrwx 1 lcluser44 lcluser44  5551443 May 21 15:20 last.pt
```

The following are samples of the "mosaic" images we used to tune the model.

Mosaicing is a technique used during training that combines multiple images into a single image to increase the variety of objects and scenes within each training batch. This helps improve the model's ability to generalize to different object sizes, aspect ratios, and contexts. (https://docs.ultralytics.com/datasets/detect/coco/)

![train_batch2](https://github.com/user-attachments/assets/69cdf7a4-fe80-4033-bb2b-8532e4e9fc97)

![train_batch90](https://github.com/user-attachments/assets/153125db-eef3-4bc6-a38a-20dd63b19260)


